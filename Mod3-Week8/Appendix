# Trying my best a learn how to use GitHub and Jupyter Notebooks. 
# Read that an appendix should be created for use of ChatGPT or other AI Assistance.
# I want to make sure that I am following the rules. Please advise if I should be doing anything differently.


# BU AI Use Policy: https://www.bu.edu/cds-faculty/culture-community/gaia-policy/
# BU APA Formatted AI Use Citation: "OpenAI. (2025). Transcript of conversation with problem-solving solutions. Unpublished interaction transcript. Retrieved from OpenAI’s ChatGPT platform. In accordance with Boston University GAIA policy."


# BU AI Use Citation Requirements:
# b) ChatGPT (Subscription) 
# c) Primarily will be using ChatGPT to prime myself for how to solution for problems within an assignment, what libraries most help with solving the problem, and then walking me through the steps to understanding how to get to the solution. ChatGPT, is helping me bridge a gap in my understand of converting course concepts to code;
# d) AI is primarily being used as a preceptor that translates teachings information into to practical development knowledge to better understand the steps to the solution, learn optimal development to a given problem to form wisdom;

# Initial Dialog: 
# Asked for help with a homework assignment using GitHub Codespaces, Python, and Jupyter Notebooks. 
# Provided libraries to be used and mentioned that I would need to cite the use of ChatGPT in the appendix.
# Requested help in step by step instructional breakdown


# a) the entire exchange, highlighting the most relevant sections;

# Problem Statements and Solution Steps Summary with Detailed Explanations

# **Transcript Summary**

# Summary: Homework 08 – Classification (Logistic Regression & Ensemble Methods)
# ------------------------------------------------------------------------------

# The objective was to build and evaluate machine learning classifiers to predict diabetes using the
# Pima Indians Diabetes dataset. The task involved creating a baseline logistic regression model and
# an ensemble method model, comparing their performance using accuracy and model evaluation tools.

# Step 1: Dataset Loading and Preprocessing
# - The dataset was loaded using `kagglehub.dataset_download()` from the Kaggle API.
# - Performed initial exploratory data analysis using `.head()`, `.info()`, `.value_counts()` and histograms
#   to understand data types, distributions, and class balance.
# - The feature matrix (X) was defined by dropping the 'Outcome' column, and the target vector (y)
#   was assigned from the 'Outcome' column.
# - Used `StandardScaler` to normalize the features, ensuring they are on a comparable scale.
# - Data was split into training and test sets using `train_test_split` with `stratify=y` to preserve class balance.

# Step 2: Logistic Regression Model
# - Created a logistic regression model using `LogisticRegression(class_weight='balanced', max_iter=1000)`.
# - Used `RepeatedStratifiedKFold` with 5 splits and 3 repeats for cross-validation to assess performance.
# - The model was trained on the training data and evaluated using accuracy, classification report, and
#   a confusion matrix to analyze prediction outcomes on the test set.
# - This baseline model helped establish a reference for accuracy and recall on both classes.

# Step 3: Ensemble Model – Random Forest
# - Random Forest was selected for its robustness, ability to model non-linear relationships, and automatic
#   handling of feature interactions and importance estimation.
# - A parameter grid was defined to tune hyperparameters such as:
#   - 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_leaf_nodes', 'ccp_alpha'
# - `GridSearchCV` was used with 5-fold cross-validation to identify the best model.
# - The model was trained using the same training split for consistency.
# - After training, model performance was evaluated on the test set using accuracy, a classification report,
#   and a confusion matrix visualization to inspect the balance between false positives and false negatives.

# Additional Notes:
# - No need to repeat the data split; earlier splits and scaling were reused to maintain consistency.
# - Runtime for GridSearchCV was expected due to the size of the hyperparameter grid (~486 combinations).
# - A reduced grid was recommended for faster debugging or experimentation.
# - The confusion matrix and classification report provided deeper insight into class-level performance,
#   especially in handling the minority class (diabetic patients).

# Summary:
# This classification task followed a clear machine learning pipeline using standard scikit-learn tools.
# The comparison between logistic regression and an ensemble model (Random Forest) demonstrated the
# added predictive power and flexibility of ensemble methods while reinforcing the importance of
# proper validation and preprocessing.